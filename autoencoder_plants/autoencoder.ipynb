{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Conv2D, MaxPooling2D, Conv2DTranspose, \\\n",
    "    concatenate, Input, Add, Concatenate, GlobalAveragePooling2D, Activation, GaussianNoise, Input, Softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "# NOTE We only train on normal data!!!!\n",
    "datapathTrain = '../data_plants/plants_binary/train/normal/'\n",
    "datapathTest =  '../data_plants/plants_binary/test/normal/'\n",
    "\n",
    "# For postprocessing\n",
    "datapathAnomalous =  '../data_plants/plants_binary/test/sick/'\n",
    "datapathVeryAnomalous =  '../data_misc/'\n",
    "\n",
    "# Input settings\n",
    "imageWidth = 240\n",
    "imageHeight = 240\n",
    "imageChannels = 3\n",
    "\n",
    "# Training parameter\n",
    "learningrate = 1e-4\n",
    "nepoches = 30\n",
    "batchSize = 10\n",
    "intermediateResults = 300\n",
    "patience = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets build a data pipeline generator\n",
    "\n",
    "The data pipeline generator is a helper class which builds tf.data.set objects tailor made for your model needs. Clearly, Keras offeres these functionality already built in, but its good to know how things work under the hood. Especially when you start working with non-standard models.\n",
    "\n",
    "The generated tf.data.set object prepares the raw data for the neural network. It also carries out image augmentation etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DatapipeGenerator:\n",
    "    def __init__(self, datapath: str):\n",
    "\n",
    "        # Save datapath\n",
    "        self.datapath = datapath\n",
    "\n",
    "        # Find all image files in datapath\n",
    "        self.filenames = []\n",
    "        for root, dirs, files in os.walk(datapath):\n",
    "            for file in files:\n",
    "                if file.endswith(\".png\") or file.endswith(\".jpg\") or file.endswith(\".jpeg\"):\n",
    "                    name = str(os.path.join(root, file))\n",
    "                    self.filenames.append(name)\n",
    "\n",
    "        self.iw, self.ih, self.ic = None, None, None\n",
    "\n",
    "\n",
    "    # ============================\n",
    "    def create(\n",
    "        self, iw: int, ih: int, ic:int, batchSize: int,\n",
    "        shuffle_buffer_size:int=50000,\n",
    "        augmentations:list=['fliph', 'flipv', 'color', 'crop', 'noise'],\n",
    "        nrepeat:int=1\n",
    "    ):\n",
    "\n",
    "        \"\"\"Creates the datapipe\"\"\"\n",
    "\n",
    "        self.iw, self.ih, self.ic = iw, ih, ic\n",
    "\n",
    "        # Let's build the pipeline\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(self.filenames)\n",
    "\n",
    "        dataset = dataset.shuffle(buffer_size=shuffle_buffer_size)\n",
    "        dataset = dataset.repeat(nrepeat)\n",
    "\n",
    "        # Load the image\n",
    "        dataset = dataset.map(self._processLoadImage)\n",
    "\n",
    "        # Add Gaussian nOise to image\n",
    "        dataset = dataset.map(self._processAddNoise)\n",
    "\n",
    "        # Augment the image\n",
    "        if 'noise' in augmentations:\n",
    "            dataset = dataset.map(self._processAddNoise)\n",
    "        if 'fliph' in augmentations:\n",
    "            dataset = dataset.map(self._processAugmentFlip)\n",
    "        if 'flipv' in augmentations:\n",
    "            dataset = dataset.map(self._processAugmentFlipVertically)\n",
    "        if 'color' in augmentations:\n",
    "            dataset = dataset.map(self._processAugmentColor)\n",
    "        if 'crop' in  augmentations:\n",
    "            dataset = dataset.map(self._processAugmentCrop)\n",
    "\n",
    "        # Apply batching\n",
    "        dataset = dataset.batch(batchSize)\n",
    "\n",
    "        # Prefetching\n",
    "        dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "\n",
    "\n",
    "    # ============================\n",
    "    def _processLoadImage(self, imgpath):\n",
    "        img = tf.io.read_file(imgpath)\n",
    "        img = tf.image.decode_jpeg(img, channels=self.ic)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        img = tf.image.resize(img, (self.ih, self.iw))\n",
    "        return img, imgpath\n",
    "\n",
    "\n",
    "    # ============================\n",
    "    def _processAddNoise(self, img, imgpath, mean=0.0, stddev=0.1):\n",
    "\n",
    "        def addnoise(img):\n",
    "            weight = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "            gnoise = tf.random.normal(shape=tf.shape(img), mean=mean, stddev=stddev, dtype=tf.float32)\n",
    "            return tf.add(img, gnoise*weight)\n",
    "\n",
    "        def nonoise(img):\n",
    "            return img\n",
    "\n",
    "        choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "        img = tf.cond(\n",
    "            choice < 0.5,\n",
    "            lambda: addnoise(img),\n",
    "            lambda: nonoise(img)\n",
    "        )\n",
    "\n",
    "        return img, imgpath\n",
    "\n",
    "    # ============================\n",
    "    def _processAugmentColor(self, img, imgpath,\n",
    "                             rand_hue=0.01, rand_saturation=[0.8,1.2],\n",
    "                             rand_brightness=0.01, rand_contrast=[0.8,1.1], **kwargs):\n",
    "\n",
    "        if self.ic == 3:\n",
    "            img = tf.image.random_hue(img, rand_hue)\n",
    "            img = tf.image.random_saturation(img, rand_saturation[0], rand_saturation[1])\n",
    "            \n",
    "        img = tf.image.random_brightness(img, rand_brightness)\n",
    "        img = tf.image.random_contrast(img, rand_contrast[0], rand_contrast[1])\n",
    "        \n",
    "        return img, imgpath\n",
    "\n",
    "\n",
    "   # ============================\n",
    "    def _processAugmentCrop(self, img, imgpath, rand_scales=[0.7, 1.0, 0.01], **kwargs):\n",
    "\n",
    "        # Generate 20 crop settings, ranging from a 1% to 20% crop.\n",
    "        def cropimage(img, width, height):\n",
    "            scales = np.arange(rand_scales[0], rand_scales[1], rand_scales[2])\n",
    "            cropboxes = np.zeros((len(scales), 4))\n",
    "            for i, scale in enumerate(scales):\n",
    "                cx1 = cy1 = 0.5 - (0.5 * scale)\n",
    "                cx2 = cy2 = 0.5 + (0.5 * scale)\n",
    "                cropboxes[i] = [cx1, cy1, cx2, cy2]\n",
    "\n",
    "            cropboxes = tf.convert_to_tensor(cropboxes, dtype=tf.float32)\n",
    "\n",
    "            # Create different crops for an image\n",
    "            crops = tf.image.crop_and_resize(\n",
    "                [img],\n",
    "                boxes=cropboxes,\n",
    "                box_indices=np.zeros(cropboxes.shape[0]),\n",
    "                crop_size=(height, width)\n",
    "            )\n",
    "\n",
    "            # Return a random crop\n",
    "            idx = tf.random.uniform(shape=[], minval=0, maxval=cropboxes.shape[0], dtype=tf.int32)\n",
    "            return crops[idx,:,:,:]\n",
    "\n",
    "        def nocrop(img):\n",
    "            return img\n",
    "\n",
    "        # =======================\n",
    "        choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "        img = tf.cond(\n",
    "            choice < 0.5,\n",
    "            lambda: nocrop(img),\n",
    "            lambda: cropimage(img, width=self.iw, height=self.ih)\n",
    "        )\n",
    "\n",
    "        return img, imgpath\n",
    "\n",
    "\n",
    "    # ============================\n",
    "    def _processAugmentFlip(self, img, imgpath):\n",
    "\n",
    "        # Flip\n",
    "        def flip(img):\n",
    "            img = tf.image.flip_left_right(img)\n",
    "            return img\n",
    "\n",
    "        def noflip(img):\n",
    "            return img\n",
    "\n",
    "        choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "        img = tf.cond(choice < 0.5,\n",
    "            lambda: noflip(img),\n",
    "            lambda: flip(img)\n",
    "        )\n",
    "\n",
    "        return img, imgpath\n",
    "\n",
    "    # ============================\n",
    "    def _processAugmentFlipVertically(self, img, imgpath):\n",
    "\n",
    "        # Flip\n",
    "        def flip(img):\n",
    "            img = tf.image.flip_up_down(img)\n",
    "            return img\n",
    "\n",
    "        def noflip(img):\n",
    "            return img\n",
    "\n",
    "        choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "        img = tf.cond(choice < 0.5,\n",
    "            lambda: noflip(img),\n",
    "            lambda: flip(img)\n",
    "        )\n",
    "\n",
    "        return img, imgpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize both Generators\n",
    "\n",
    "datapipeGenTrain = DatapipeGenerator(datapath=datapathTrain)\n",
    "datapipeGenTest  = DatapipeGenerator(datapath=datapathTest)\n",
    "datapipeGenAnomalous = DatapipeGenerator(datapath=datapathAnomalous)\n",
    "datapipeGenVeryAnomalous = DatapipeGenerator(datapath=datapathVeryAnomalous)\n",
    "\n",
    "dpTrain = datapipeGenTrain.create(\n",
    "    iw=imageWidth,\n",
    "    ih=imageHeight,\n",
    "    ic=imageChannels,\n",
    "    batchSize=batchSize,\n",
    "    augmentations=['fliph', 'flipv', 'color', 'crop', 'noise']\n",
    ")\n",
    "\n",
    "dpTest = datapipeGenTest.create(\n",
    "    iw=imageWidth,\n",
    "    ih=imageHeight,\n",
    "    ic=imageChannels,\n",
    "    batchSize=batchSize,\n",
    "    augmentations=[] # No augmentations on the test data set!\n",
    ")\n",
    "\n",
    "dpAnomalous = datapipeGenAnomalous.create(\n",
    "    iw=imageWidth,\n",
    "    ih=imageHeight,\n",
    "    ic=imageChannels,\n",
    "    batchSize=batchSize,\n",
    "    augmentations=[] # No augmentations on the test data set!\n",
    ")\n",
    "\n",
    "dpVeryAnomalous = datapipeGenVeryAnomalous.create(\n",
    "    iw=imageWidth,\n",
    "    ih=imageHeight,\n",
    "    ic=imageChannels,\n",
    "    batchSize=batchSize,\n",
    "    augmentations=[] # No augmentations on the test data set!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's show how to use and test our pipeline\n",
    "\n",
    "for it, (imgs, paths) in enumerate(dpTrain):\n",
    "    \n",
    "    fig, axs = plt.subplots(1,4, figsize=(15,15))\n",
    "    for b in range(4):\n",
    "        axs[b].imshow(imgs[b,...].numpy())\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    break # Break or wait until the end of days..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build a wrapper for the autencoder\n",
    "\n",
    "Wrap the keras model and all methods required for training in one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time we outsource some stuff...\n",
    "\n",
    "from bottleneck import Nonbt1d    # Bottleneck module\n",
    "from downsample import Downsample # Downsample module\n",
    "from upsample import Upsample     # Upsample module\n",
    "\n",
    "\n",
    "class AutoencoderWrapper:\n",
    "    def __init__(self, iw, ih, ic=3, learnRate=0.001):\n",
    "\n",
    "        self.iw = iw\n",
    "        self.ih = ih\n",
    "        self.ic = ic\n",
    "\n",
    "        self.model = None\n",
    "\n",
    "        # Build the model\n",
    "        self._buildModel()\n",
    "        \n",
    "        # Pick an optimizer\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learnRate)\n",
    "\n",
    "    def _buildModel(self):\n",
    "        \"\"\"Build the modelWithoutPosthead\"\"\"\n",
    "        \n",
    "        # Feature extractor\n",
    "        inputs = Input((self.ih, self.iw, self.ic))\n",
    "        \n",
    "        # Encoder\n",
    "        d1 = Downsample(8, kernelsize=(3,3), maxpoolsize=(2,2), strides=(2,2))(inputs)\n",
    "        d2 = Downsample(16, kernelsize=(3,3), maxpoolsize=(2,2), strides=(2,2))(d1)\n",
    "        d3 = Downsample(32, kernelsize=(3,3), maxpoolsize=(2,2), strides=(2,2))(d2)\n",
    "        d4 = Downsample(64, kernelsize=(3,3), maxpoolsize=(2,2), strides=(2,2))(d3)\n",
    "        b4 = Nonbt1d(nfilters=64)(d4)\n",
    "\n",
    "        \n",
    "        # Decoder\n",
    "        u19 = Upsample(32, (2, 2), strides=(2, 2), padding='same')(b4)\n",
    "        u20 = Upsample(16, (2, 2), strides=(2, 2), padding='same')(u19)\n",
    "        u20 = Dropout(0.5)(u20)\n",
    "        b21 = Nonbt1d(nfilters=16)(u20)\n",
    "        u22 = Upsample(8, (2, 2), strides=(2, 2), padding='same')(b21)\n",
    "        u22 = Dropout(0.5)(u22)\n",
    "        b23 = Nonbt1d(nfilters=8)(u22)\n",
    "        u22 = Upsample(self.ic, (2, 2), strides=(2, 2), padding='same', activation='sigmoid')(b23)\n",
    "\n",
    "        # Model with final heatmap classification\n",
    "        self.model = Model(inputs=[inputs], outputs=u22)\n",
    "\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def loss(self, ytrue, ypred):\n",
    "        return tf.reduce_mean(tf.square(ypred-ytrue))\n",
    "  \n",
    "    @tf.function\n",
    "    def trainStep(self, imgs, ytrue):\n",
    "        \n",
    "        # Calculate gradients of loss wrt to imgs\n",
    "        with tf.GradientTape() as t:\n",
    "            ypred = self.model(imgs)\n",
    "            loss = self.loss(ytrue, ypred)\n",
    "\n",
    "        # Change weightsPretrainedImageNet\n",
    "        grads = t.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        return ypred, loss\n",
    "\n",
    "    @tf.function\n",
    "    def testStep(self, imgs, ytrue):\n",
    "        ypred = self.model(imgs)\n",
    "        loss = self.loss(ytrue, ypred)\n",
    "        return ypred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our Model Wrap\n",
    "autoencoderWrap = AutoencoderWrapper(\n",
    "    iw = imageWidth,\n",
    "    ih = imageHeight,\n",
    "    ic = imageChannels,\n",
    "    learnRate = learningrate\n",
    ")\n",
    "\n",
    "# print model summary\n",
    "print(autoencoderWrap.model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsloop starts here\n",
    "\n",
    "lossTrain, lossTest = [[],[]], [[],[]]\n",
    "bestTestLoss, earlyStoppingCtr = 1e+4, 0\n",
    "\n",
    "# Load weights if exist\n",
    "if os.path.isfile(\"./weightsBest.h5\"):\n",
    "    try:\n",
    "         autoencoderWrap.model.load_weights(\"./weightsBest.h5\")\n",
    "    except:\n",
    "        print(\"Wegight load failed! Have you changed your model architecture?\")\n",
    "        \n",
    "for e in range(nepoches):\n",
    "    print(f\"Starting epoche {e}\")\n",
    "\n",
    "\n",
    "    # =====================\n",
    "    # Run Training data set\n",
    "    print(\"Start Traing\")\n",
    "    \n",
    "    # Loop through dataset\n",
    "    for it, (imgs, paths) in enumerate(dpTrain):\n",
    "        \n",
    "        # Run a train step\n",
    "        pred, loss = autoencoderWrap.trainStep(imgs=imgs, ytrue=imgs)\n",
    "        \n",
    "        # Log results\n",
    "        lossTrain[0].append(e * len(dpTrain) + it)\n",
    "        lossTrain[1].append(loss.numpy())\n",
    "    \n",
    "        # Write out intermediate results\n",
    "        if (e * len(dpTrain) + it) % intermediateResults == 0:\n",
    "                \n",
    "            print(f\"Train - Epoche: {e}, Iteration: {it}/{len(dpTrain)}, TrainLoss: {loss.numpy():.7f}\")\n",
    "    \n",
    "    \n",
    "    # =====================\n",
    "    # Run test data set:\n",
    "    print(\"Start Testing\")\n",
    "    \n",
    "    lossMean = 0\n",
    "    \n",
    "    # Loop through dataset\n",
    "    for it, (imgs, paths) in enumerate(dpTest):\n",
    "            \n",
    "        # Run a test step\n",
    "        pred, loss = autoencoderWrap.testStep(imgs=imgs, ytrue=imgs)\n",
    "        lossMean += loss.numpy()/len(dpTest)\n",
    "\n",
    "    lossTest[0].append((e+1) * len(dpTrain))\n",
    "    lossTest[1].append(lossMean)\n",
    "    \n",
    "    \n",
    "    # Finally plot some images\n",
    "    imgs = imgs.numpy()\n",
    "\n",
    "    fig, axs = plt.subplots(2,4, figsize=(15,7))\n",
    "    for b in range(min([4,imgs.shape[0]])):\n",
    "        axs[0,b].imshow(imgs[b,...])\n",
    "        axs[1,b].imshow(pred[b,...])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # For early stopping\n",
    "    if lossMean < bestTestLoss:\n",
    "        bestTestLoss = lossMean\n",
    "        earlyStoppingCtr = 0\n",
    "        autoencoderWrap.model.save_weights(\"./weightsBest.h5\")\n",
    "        \n",
    "    else:\n",
    "        earlyStoppingCtr += 1\n",
    "    \n",
    "    print(f\"Test  - Epoche: {e}, TestLoss: {lossMean:.7f}, BestLoss: {bestTestLoss:.7f}, EarlyStoppingCtr {earlyStoppingCtr}/{patience}\")\n",
    "    \n",
    "    \n",
    "    # =====================\n",
    "    # Early Stopping\n",
    "    if earlyStoppingCtr >= patience:\n",
    "        print(\"Maximum patience reached. Stopping training\")\n",
    "        break\n",
    "        \n",
    "    # =====================\n",
    "    # Plot losses\n",
    "    fig, axs = plt.subplots(1, figsize=(15,7))\n",
    "    axs.plot(lossTrain[0],lossTrain[1],'b-')\n",
    "    axs.plot(lossTest[0],lossTest[1],'r-')\n",
    "    axs.set_yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights if exist\n",
    "if os.path.isfile(\"./weightsBest.h5\"):\n",
    "    autoencoderWrap.model.load_weights(\"./weightsBest.h5\")\n",
    "\n",
    "\n",
    "    \n",
    "# Loop through dataset\n",
    "display(HTML('<h1>Normal data</h1>'))\n",
    "for it, (imgs, paths) in enumerate(dpTest):\n",
    "\n",
    "    # Predict\n",
    "    pred = autoencoderWrap.model.predict(imgs)\n",
    "    break\n",
    "    \n",
    "# Finally plot some images\n",
    "imgs = imgs.numpy()\n",
    "error = np.clip(np.abs(pred-imgs).mean(axis=-1), 0, 1)\n",
    "\n",
    "fig, axs = plt.subplots(3,4, figsize=(15,7))\n",
    "for b in range(min([4,imgs.shape[0]])):\n",
    "    axs[0,b].imshow(imgs[b,...])\n",
    "    axs[0,b].set_xticks([])\n",
    "    axs[0,b].set_yticks([])\n",
    "    axs[0,b].title.set_text(f\"Original\")\n",
    "    axs[1,b].imshow(pred[b,...])\n",
    "    axs[1,b].set_xticks([])\n",
    "    axs[1,b].set_yticks([])\n",
    "    axs[1,b].title.set_text(f\"Reconstructed\")\n",
    "    axs[2,b].imshow(error[b,...], cmap=\"gray\")\n",
    "    axs[2,b].title.set_text(f\"Error: {np.mean(error[b,...]):.3f}\")\n",
    "    axs[2,b].set_xticks([])\n",
    "    axs[2,b].set_yticks([])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "# Loop through dataset\n",
    "display(HTML('<h1>Anomalous data</h1>'))\n",
    "for it, (imgs, paths) in enumerate(dpAnomalous):\n",
    "\n",
    "    # Predict\n",
    "    pred = autoencoderWrap.model.predict(imgs)\n",
    "    break\n",
    "    \n",
    "# Finally plot some images\n",
    "imgs = imgs.numpy()\n",
    "error = np.clip(np.abs(pred-imgs).mean(axis=-1), 0, 1)\n",
    "\n",
    "fig, axs = plt.subplots(3,4, figsize=(15,7))\n",
    "for b in range(min([4,imgs.shape[0]])):\n",
    "    axs[0,b].imshow(imgs[b,...])\n",
    "    axs[0,b].set_xticks([])\n",
    "    axs[0,b].set_yticks([])\n",
    "    axs[0,b].title.set_text(f\"Original\")\n",
    "    axs[1,b].imshow(pred[b,...])\n",
    "    axs[1,b].set_xticks([])\n",
    "    axs[1,b].set_yticks([])\n",
    "    axs[1,b].title.set_text(f\"Reconstructed\")\n",
    "    axs[2,b].imshow(error[b,...], cmap=\"gray\")\n",
    "    axs[2,b].title.set_text(f\"Error: {np.mean(error[b,...]):.3f}\")\n",
    "    axs[2,b].set_xticks([])\n",
    "    axs[2,b].set_yticks([])\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "# Loop through dataset\n",
    "display(HTML('<h1>Very anomalous data</h1>'))\n",
    "for it, (imgs, paths) in enumerate(dpVeryAnomalous):\n",
    "\n",
    "    # Predict\n",
    "    pred = autoencoderWrap.model.predict(imgs)\n",
    "\n",
    "    \n",
    "# Finally plot some images\n",
    "imgs = imgs.numpy()\n",
    "error = np.clip(np.abs(pred-imgs).mean(axis=-1), 0, 1)\n",
    "\n",
    "fig, axs = plt.subplots(3,4, figsize=(15,7))\n",
    "for b in range(min([4,imgs.shape[0]])):\n",
    "    axs[0,b].imshow(imgs[b,...])\n",
    "    axs[0,b].set_xticks([])\n",
    "    axs[0,b].set_yticks([])\n",
    "    axs[0,b].title.set_text(f\"Original\")\n",
    "    axs[1,b].imshow(pred[b,...])\n",
    "    axs[1,b].set_xticks([])\n",
    "    axs[1,b].set_yticks([])\n",
    "    axs[1,b].title.set_text(f\"Reconstructed\")\n",
    "    axs[2,b].imshow(error[b,...], cmap=\"gray\")\n",
    "    axs[2,b].title.set_text(f\"Error: {np.mean(error[b,...]):.3f}\")\n",
    "    axs[2,b].set_xticks([])\n",
    "    axs[2,b].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
