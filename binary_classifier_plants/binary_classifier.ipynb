{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Conv2D, MaxPooling2D, Conv2DTranspose, \\\n",
    "    concatenate, Input, Add, Concatenate, GlobalAveragePooling2D, Activation, GaussianNoise, Input, Softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "classNames = [\"normal\", \"sick\"]\n",
    "datapathTrain = '../data_plants/plants_binary/train/'\n",
    "datapathTest =  '../data_plants/plants_binary/test/'\n",
    "\n",
    "# Input settings\n",
    "imageWidth = 240\n",
    "imageHeight = 240\n",
    "imageChannels = 3\n",
    "\n",
    "# Training parameter\n",
    "learningrate = 1e-4\n",
    "nepoches = 5\n",
    "batchSize = 10\n",
    "intermediateResults = 600\n",
    "patience = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets build a data pipeline generator\n",
    "\n",
    "The data pipeline generator is a helper class which builds tf.data.set objects tailor made for your model needs. Clearly, Keras offeres these functionality already built in, but its good to know how things work under the hood. Especially when you start working with non-standard models.\n",
    "\n",
    "The generated tf.data.set object prepares the raw data for the neural network. It also carries out image augmentation etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatapipeGenerator:\n",
    "    def __init__(self, datapath: str, classNames:list=[]):\n",
    "\n",
    "        # Save datapath and classnames\n",
    "        self.datapath = datapath\n",
    "        self.classNames = classNames\n",
    "\n",
    "        # Find all image files in datapath\n",
    "        self.filenames = []\n",
    "        for root, dirs, files in os.walk(datapath):\n",
    "            for file in files:\n",
    "                if file.endswith(\".png\") or file.endswith(\".jpg\") or file.endswith(\".jpeg\"):\n",
    "                    name = str(os.path.join(root, file))\n",
    "                    self.filenames.append(name)\n",
    "\n",
    "        self.iw, self.ih, self.ic = None, None, None\n",
    "\n",
    "    # ============================\n",
    "    @property\n",
    "    def cdict(self):\n",
    "        return {k:v for v,k in enumerate(sorted(self.classNames))}\n",
    "\n",
    "\n",
    "    # ============================\n",
    "    def create(\n",
    "        self, iw: int, ih: int, ic:int, batchSize: int,\n",
    "        shuffle_buffer_size:int=10000,\n",
    "        augmentations:list=['fliph', 'flipv', 'color', 'crop', 'noise'],\n",
    "        nrepeat:int=1\n",
    "    ):\n",
    "\n",
    "        \"\"\"Creates the datapipe\"\"\"\n",
    "\n",
    "        self.iw, self.ih, self.ic = iw, ih, ic\n",
    "\n",
    "        # Let's build the pipeline\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(self.filenames)\n",
    "\n",
    "        dataset = dataset.shuffle(buffer_size=shuffle_buffer_size)\n",
    "        dataset = dataset.repeat(nrepeat)\n",
    "\n",
    "        # Load the image\n",
    "        dataset = dataset.map(self._processLoadImage)\n",
    "\n",
    "        # Add Gaussian nOise to image\n",
    "        dataset = dataset.map(self._processAddNoise)\n",
    "\n",
    "        # Augment the image\n",
    "        if 'noise' in augmentations:\n",
    "            dataset = dataset.map(self._processAddNoise)\n",
    "        if 'fliph' in augmentations:\n",
    "            dataset = dataset.map(self._processAugmentFlip)\n",
    "        if 'flipv' in augmentations:\n",
    "            dataset = dataset.map(self._processAugmentFlipVertically)\n",
    "        if 'color' in augmentations:\n",
    "            dataset = dataset.map(self._processAugmentColor)\n",
    "        if 'crop' in  augmentations:\n",
    "            dataset = dataset.map(self._processAugmentCrop)\n",
    "\n",
    "        # Apply batching\n",
    "        dataset = dataset.batch(batchSize)\n",
    "\n",
    "        # Prefetching\n",
    "        dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    \n",
    "    # ============================\n",
    "    def _lookUpClass(self, imgpath):\n",
    "        # Split the string and take the second last element as class name\n",
    "        imgClass = tf.strings.split(imgpath, '/')[-2]\n",
    "        imgClass = imgClass.numpy().decode(\"utf-8\")\n",
    "        idx = self.cdict[imgClass]\n",
    "        return idx\n",
    "\n",
    "    # ============================\n",
    "    def _processLoadImage(self, imgpath):\n",
    "\n",
    "        img = tf.io.read_file(imgpath)\n",
    "        img = tf.image.decode_jpeg(img, channels=self.ic)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        img = tf.image.resize(img, (self.ih, self.iw))\n",
    "\n",
    "        idx = tf.py_function(self._lookUpClass, [imgpath], tf.int32)\n",
    "        label = tf.one_hot(idx, len(self.classNames))\n",
    "        return img, label, imgpath\n",
    "\n",
    "\n",
    "    # ============================\n",
    "    def _processAddNoise(self, img, label, imgpath, mean=0.0, stddev=0.1):\n",
    "\n",
    "        def addnoise(img):\n",
    "            weight = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "            gnoise = tf.random.normal(shape=tf.shape(img), mean=mean, stddev=stddev, dtype=tf.float32)\n",
    "            return tf.add(img, gnoise*weight)\n",
    "\n",
    "        def nonoise(img):\n",
    "            return img\n",
    "\n",
    "        choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "        img = tf.cond(\n",
    "            choice < 0.5,\n",
    "            lambda: addnoise(img),\n",
    "            lambda: nonoise(img)\n",
    "        )\n",
    "\n",
    "        return img, label, imgpath\n",
    "\n",
    "    # ============================\n",
    "    def _processAugmentColor(self, img, label, imgpath,\n",
    "                             rand_hue=0.01, rand_saturation=[0.8,1.2],\n",
    "                             rand_brightness=0.01, rand_contrast=[0.8,1.1], **kwargs):\n",
    "\n",
    "        if self.ic == 3:\n",
    "            img = tf.image.random_hue(img, rand_hue)\n",
    "            img = tf.image.random_saturation(img, rand_saturation[0], rand_saturation[1])\n",
    "            \n",
    "        img = tf.image.random_brightness(img, rand_brightness)\n",
    "        img = tf.image.random_contrast(img, rand_contrast[0], rand_contrast[1])\n",
    "        \n",
    "        return img, label, imgpath\n",
    "\n",
    "\n",
    "   # ============================\n",
    "    def _processAugmentCrop(self, img, label, imgpath, rand_scales=[0.7, 1.0, 0.01], **kwargs):\n",
    "\n",
    "        # Generate 20 crop settings, ranging from a 1% to 20% crop.\n",
    "        def cropimage(img, width, height):\n",
    "            scales = np.arange(rand_scales[0], rand_scales[1], rand_scales[2])\n",
    "            cropboxes = np.zeros((len(scales), 4))\n",
    "            for i, scale in enumerate(scales):\n",
    "                cx1 = cy1 = 0.5 - (0.5 * scale)\n",
    "                cx2 = cy2 = 0.5 + (0.5 * scale)\n",
    "                cropboxes[i] = [cx1, cy1, cx2, cy2]\n",
    "\n",
    "            cropboxes = tf.convert_to_tensor(cropboxes, dtype=tf.float32)\n",
    "\n",
    "            # Create different crops for an image\n",
    "            crops = tf.image.crop_and_resize(\n",
    "                [img],\n",
    "                boxes=cropboxes,\n",
    "                box_indices=np.zeros(cropboxes.shape[0]),\n",
    "                crop_size=(height, width)\n",
    "            )\n",
    "\n",
    "            # Return a random crop\n",
    "            idx = tf.random.uniform(shape=[], minval=0, maxval=cropboxes.shape[0], dtype=tf.int32)\n",
    "            return crops[idx,:,:,:]\n",
    "\n",
    "        def nocrop(img):\n",
    "            return img\n",
    "\n",
    "        # =======================\n",
    "        choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "        img = tf.cond(\n",
    "            choice < 0.5,\n",
    "            lambda: nocrop(img),\n",
    "            lambda: cropimage(img, width=self.iw, height=self.ih)\n",
    "        )\n",
    "\n",
    "        return img, label, imgpath\n",
    "\n",
    "\n",
    "    # ============================\n",
    "    def _processAugmentFlip(self, img, label, imgpath):\n",
    "\n",
    "        # Flip\n",
    "        def flip(img):\n",
    "            img = tf.image.flip_left_right(img)\n",
    "            return img\n",
    "\n",
    "        def noflip(img):\n",
    "            return img\n",
    "\n",
    "        choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "        img = tf.cond(choice < 0.5,\n",
    "            lambda: noflip(img),\n",
    "            lambda: flip(img)\n",
    "        )\n",
    "\n",
    "        return img, label, imgpath\n",
    "\n",
    "    # ============================\n",
    "    def _processAugmentFlipVertically(self, img, label, imgpath):\n",
    "\n",
    "        # Flip\n",
    "        def flip(img):\n",
    "            img = tf.image.flip_up_down(img)\n",
    "            return img\n",
    "\n",
    "        def noflip(img):\n",
    "            return img\n",
    "\n",
    "        choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "        img = tf.cond(choice < 0.5,\n",
    "            lambda: noflip(img),\n",
    "            lambda: flip(img)\n",
    "        )\n",
    "\n",
    "        return img, label, imgpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize both Generators\n",
    "\n",
    "datapipeGenTrain = DatapipeGenerator(datapath=datapathTrain, classNames=classNames)\n",
    "datapipeGenTest  = DatapipeGenerator(datapath=datapathTest, classNames=classNames)\n",
    "\n",
    "\n",
    "dpTrain = datapipeGenTrain.create(\n",
    "    iw=imageWidth,\n",
    "    ih=imageHeight,\n",
    "    ic=imageChannels,\n",
    "    batchSize=batchSize,\n",
    "    augmentations=['fliph', 'flipv', 'color', 'crop', 'noise']\n",
    ")\n",
    "\n",
    "dpTest = datapipeGenTest.create(\n",
    "    iw=imageWidth,\n",
    "    ih=imageHeight,\n",
    "    ic=imageChannels,\n",
    "    batchSize=batchSize,\n",
    "    augmentations=[] # No augmentations on the test data set!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's show how to use and test our pipeline\n",
    "\n",
    "for it, (imgs, labels, paths) in enumerate(dpTrain):\n",
    "    \n",
    "    fig, axs = plt.subplots(1,4, figsize=(15,15))\n",
    "    for b in range(4):\n",
    "        axs[b].imshow(imgs[b,...].numpy())\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    break # Break or wait until the end of days..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build a wrapper for the binary classifier\n",
    "\n",
    "Wrap the keras model and all methods required for training in one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierWrapper:\n",
    "    def __init__(self, nc, iw, ih, ic=3, learnRate=0.001):\n",
    "        self.nc = nc\n",
    "        self.iw = iw\n",
    "        self.ih = ih\n",
    "        self.ic = ic\n",
    "\n",
    "        self.model = None\n",
    "\n",
    "        # Build the model\n",
    "        self._buildModel()\n",
    "        \n",
    "        # Pick an optimizer\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learnRate)\n",
    "\n",
    "    def _buildModel(self):\n",
    "        \"\"\"Build the modelWithoutPosthead\"\"\"\n",
    "        \n",
    "        # Feature extractor\n",
    "        inputs = Input((self.ih, self.iw, self.ic))\n",
    "        \n",
    "        c1 = Conv2D(64, (3, 3), activation='relu', padding='same', name=\"Conv1\", strides=(2, 2))(inputs)\n",
    "        p1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name=\"pool1\")(c1)\n",
    "\n",
    "        f2s1 = Conv2D(16, (1, 1), activation='relu', padding='same', name=\"Fire2s1\")(p1)\n",
    "        f2e1 = Conv2D(64, (1, 1), activation='relu', padding='same', name=\"Fire2e1\")(f2s1)\n",
    "        f2e3 = Conv2D(64, (3, 3), activation='relu', padding='same', name=\"Fire2e3\")(f2s1)\n",
    "        f2 = Concatenate(name=\"Fire2cat\")([f2e1, f2e3])\n",
    "\n",
    "        f3s1 = Conv2D(16, (1, 1), activation='relu', padding='same', name=\"Fire3s1\")(f2)\n",
    "        f3e1 = Conv2D(64, (1, 1), activation='relu', padding='same', name=\"Fire3e1\")(f3s1)\n",
    "        f3e3 = Conv2D(64, (3, 3), activation='relu', padding='same', name=\"Fire3e3\")(f3s1)\n",
    "        f3 = Concatenate(name=\"Fire3cat\")([f3e1, f3e3])\n",
    "\n",
    "        \n",
    "        # Classification head\n",
    "        x = Dropout(0.5, name='drop9')(f3)\n",
    "        heatmap = Conv2D(self.nc, (1, 1), padding='valid', name='heatmap', activation='linear')(x)\n",
    "        logits = GlobalAveragePooling2D()(heatmap)\n",
    "\n",
    "        # Model with final heatmap classification\n",
    "        self.model = Model(inputs=[inputs], outputs=logits)\n",
    "\n",
    "\n",
    "    def getHeatmapDetector(self):\n",
    "        \"\"\"Double headed module for anomaly detection\"\"\"\n",
    "        heatmap = self.model.layers[-2]\n",
    "        logits = self.model.layers[-1]\n",
    "        return Model(inputs=[self.model.input], outputs=[heatmap.output, logits.output])\n",
    "\n",
    "\n",
    "    def annoteTraining(self, imgs, ytrue):\n",
    "        \"\"\"For training only\"\"\"\n",
    "\n",
    "        # Calculate Heatmap\n",
    "        model = self.getHeatmapDetector()\n",
    "        hm, ypred = model.predict(imgs)\n",
    "\n",
    "        # Normalize heatmap\n",
    "        probs = tf.expand_dims(tf.expand_dims(tf.one_hot(tf.argmax(ypred, axis=-1), self.nc),1),1)\n",
    "        anomalies = tf.image.resize(hm, (self.ih, self.iw))\n",
    "        anomalies = tf.multiply(anomalies, probs)\n",
    "        anomalies = tf.reduce_sum(anomalies, axis=-1)\n",
    "        amin = tf.expand_dims(tf.expand_dims(tf.reduce_min(anomalies, axis=[1,2]),1), -1)\n",
    "        amax = tf.expand_dims(tf.expand_dims(tf.reduce_max(anomalies, axis=[1,2]),1), -1)\n",
    "        anomalies = (anomalies - amin) / (amax - amin)\n",
    "        anomalies = tf.constant((1.0,0.0,0.0))*tf.tile(tf.expand_dims(anomalies,-1), [1,1,1,3])\n",
    "\n",
    "\n",
    "        if not isinstance(imgs, np.ndarray):\n",
    "            imgs = imgs.numpy()\n",
    "\n",
    "        x0, y0 = int(0.1*imgs.shape[2]), 20\n",
    "\n",
    "        for n in range(imgs.shape[0]):\n",
    "            \n",
    "            labelTrue = f\"{tf.argmax(ytrue[n, ...]).numpy()}\"\n",
    "            labelPred = f\"{tf.argmax(ypred[n, ...]).numpy()}\"\n",
    "\n",
    "            imgs[n,...] = cv2.addWeighted(imgs[n,...], 1.0, anomalies[n,...].numpy(), 1.0, 0.0)\n",
    "\n",
    "            imgs[n,...] = cv2.putText(imgs[n,...], f\"True: {labelTrue}\", (x0, y0), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                              fontScale=0.5, color=(0, 255, 0), thickness=1)\n",
    "\n",
    "            imgs[n,...] = cv2.putText(imgs[n,...], f\"Pred: {labelPred}\", (x0, y0+20), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                              fontScale=0.5, color=(255, 0, 0), thickness=1)\n",
    "\n",
    "\n",
    "        return imgs\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def loss(self, ytrue, logits):\n",
    "        return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(ytrue, logits))\n",
    "  \n",
    "    @tf.function\n",
    "    def trainStep(self, imgs, ytrue):\n",
    "        \n",
    "        # Calculate gradients of loss wrt to imgs\n",
    "        with tf.GradientTape() as t:\n",
    "            ypred = self.model(imgs)\n",
    "            loss = self.loss(ytrue, ypred)\n",
    "\n",
    "        # Change weightsPretrainedImageNet\n",
    "        grads = t.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        return ypred, loss\n",
    "\n",
    "    @tf.function\n",
    "    def testStep(self, imgs, ytrue):\n",
    "        ypred = self.model(imgs)\n",
    "        loss = self.loss(ytrue, ypred)\n",
    "        return ypred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our Model Wrap\n",
    "classyWrap = ClassifierWrapper(\n",
    "    nc = len(classNames),\n",
    "    iw = imageWidth,\n",
    "    ih = imageHeight,\n",
    "    ic = imageChannels,\n",
    "    learnRate = learningrate\n",
    ")\n",
    "\n",
    "# print model summary\n",
    "print(classyWrap.model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train our model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsloop starts here\n",
    "\n",
    "lossTrain, lossTest = [[],[]], [[],[]]\n",
    "bestTestLoss, earlyStoppingCtr = 1e+4, 0\n",
    "\n",
    "# Load weights if exist\n",
    "if os.path.isfile(\"./weightsBest.h5\"):\n",
    "    classyWrap.model.load_weights(\"./weightsBest.h5\")\n",
    "\n",
    "for e in range(nepoches):\n",
    "    print(f\"Starting epoche {e}\")\n",
    "\n",
    "\n",
    "    # =====================\n",
    "    # Run Training data set\n",
    "    print(\"Start Traing\")\n",
    "    \n",
    "    # Loop through dataset\n",
    "    for it, (imgs, labels, paths) in enumerate(dpTrain):\n",
    "        \n",
    "        # Run a train step\n",
    "        pred, loss = classyWrap.trainStep(imgs=imgs, ytrue=labels)\n",
    "        \n",
    "        # Log results\n",
    "        lossTrain[0].append(e * len(dpTrain) + it)\n",
    "        lossTrain[1].append(loss.numpy())\n",
    "    \n",
    "        # Write out intermediate results\n",
    "        if (e * len(dpTrain) + it) % intermediateResults == 0:\n",
    "                \n",
    "            print(f\"Train - Epoche: {e}, Iteration: {it}/{len(dpTrain)}, TrainLoss: {loss.numpy():.7f}\")\n",
    "    \n",
    "    \n",
    "    # =====================\n",
    "    # Run test data set:\n",
    "    print(\"Start Testing\")\n",
    "    \n",
    "    lossMean = 0\n",
    "    \n",
    "    # Loop through dataset\n",
    "    for it, (imgs, labels, paths) in enumerate(dpTest):\n",
    "            \n",
    "        # Run a test step\n",
    "        pred, loss = classyWrap.testStep(imgs=imgs, ytrue=labels)\n",
    "        lossMean += loss.numpy()/len(dpTest)\n",
    "\n",
    "    lossTest[0].append((e+1) * len(dpTrain))\n",
    "    lossTest[1].append(lossMean)\n",
    "    \n",
    "    \n",
    "    # Finally plot some images\n",
    "    imgsAnno = classyWrap.annoteTraining(imgs, ytrue=labels)\n",
    "    imgs = imgs.numpy()\n",
    "\n",
    "    fig, axs = plt.subplots(2,4, figsize=(15,7))\n",
    "    for b in range(min([4,imgs.shape[0]])):\n",
    "        axs[0,b].imshow(imgs[b,...])\n",
    "        axs[1,b].imshow(imgsAnno[b,...])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # For early stopping\n",
    "    if lossMean < bestTestLoss:\n",
    "        bestTestLoss = lossMean\n",
    "        earlyStoppingCtr = 0\n",
    "        classyWrap.model.save_weights(\"./weightsBest.h5\")\n",
    "        \n",
    "    else:\n",
    "        earlyStoppingCtr += 1\n",
    "    \n",
    "    print(f\"Test  - Epoche: {e}, TestLoss: {lossMean:.7f}, BestLoss: {bestTestLoss:.7f}, EarlyStoppingCtr {earlyStoppingCtr}/{patience}\")\n",
    "    \n",
    "    \n",
    "    # =====================\n",
    "    # Early Stopping\n",
    "    if earlyStoppingCtr >= patience:\n",
    "        print(\"Maximum patience reached. Stopping training\")\n",
    "        break\n",
    "        \n",
    "    # =====================\n",
    "    # Plot losses\n",
    "    fig, axs = plt.subplots(1, figsize=(15,7))\n",
    "    axs.plot(lossTrain[0],lossTrain[1],'b-')\n",
    "    axs.plot(lossTest[0],lossTest[1],'r-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelWithHeatMap = classyWrap.getHeatmapDetector()\n",
    "modelWithHeatMap.load_weights(\"./weightsBest.h5\")\n",
    "\n",
    "print(\"Model outputs: \")\n",
    "print(modelWithHeatMap.outputs)\n",
    "\n",
    "\n",
    "# Loop through dataset\n",
    "for it, (imgs, labels, paths) in enumerate(dpTest):\n",
    "\n",
    "    \n",
    "    heatmap, ypred = modelWithHeatMap.predict(imgs)\n",
    "    \n",
    "    # Normalize heatmap\n",
    "    probs = tf.expand_dims(tf.expand_dims(tf.one_hot(tf.argmax(ypred, axis=-1), len(classNames)),1),1)\n",
    "    heatmap = tf.image.resize(heatmap, (imageHeight, imageWidth))\n",
    "    heatmap = tf.multiply(heatmap, probs)\n",
    "    heatmap = tf.reduce_sum(heatmap, axis=-1)\n",
    "    amin = tf.expand_dims(tf.expand_dims(tf.reduce_min(heatmap, axis=[1,2]),1), -1)\n",
    "    amax = tf.expand_dims(tf.expand_dims(tf.reduce_max(heatmap, axis=[1,2]),1), -1)\n",
    "    heatmap = (heatmap - amin) / (amax - amin)\n",
    "    heatmap = tf.constant((1.0,0.0,0.0))*tf.tile(tf.expand_dims(heatmap,-1), [1,1,1,3])\n",
    "\n",
    "\n",
    "    # Annotate it\n",
    "    if not isinstance(imgs, np.ndarray):\n",
    "        imgs = imgs.numpy()\n",
    "\n",
    "    for n in range(imgs.shape[0]):\n",
    "        if tf.argmax(labels[n,:]).numpy() == 0:\n",
    "            continue\n",
    "        \n",
    "        mask = (255*(heatmap[n,:,:,0].numpy()>0.5)).astype(np.uint8)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        contours_poly = [None]*len(contours)\n",
    "        boundRect = [None]*len(contours)\n",
    "        centers = [None]*len(contours)\n",
    "        radius = [None]*len(contours)\n",
    "        for i, c in enumerate(contours):\n",
    "            contours_poly[i] = cv2.approxPolyDP(c, 3, True)\n",
    "            boundRect[i] = cv2.boundingRect(contours_poly[i])\n",
    "            centers[i], radius[i] = cv2.minEnclosingCircle(contours_poly[i])\n",
    "\n",
    "        for i in range(len(contours)):\n",
    "            color = (255, 0, 0)\n",
    "            cv2.drawContours(imgs[n,...], contours_poly, i, color)\n",
    "            cv2.rectangle(imgs[n,...], (int(boundRect[i][0]), int(boundRect[i][1])), \\\n",
    "              (int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])), color, 2)\n",
    "\n",
    "\n",
    "    # Plot it\n",
    "    fig, axs = plt.subplots(1,4, figsize=(15,7))\n",
    "    for b in range(4):\n",
    "        \n",
    "        axs[b].imshow(imgs[b,...])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
